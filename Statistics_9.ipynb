{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7c6445-549f-4caf-a366-0f2408bc81b2",
   "metadata": {},
   "source": [
    "ASSIGNMENT: STATISTICS-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa9344-a572-4393-bf74-e401d6b0303e",
   "metadata": {},
   "source": [
    "1.  Explain the assumptions required to use ANOVA and provide examples of violations that could impact \n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0d7bc-36f9-45d4-9377-656b37a484ee",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means of two or more groups. The ANOVA assumes that the data is normally distributed, the variances of the groups are equal, and the observations are independent. The following are the assumptions required to use ANOVA:\n",
    "\n",
    "Normality: The data must be normally distributed. This means that the distribution of the dependent variable within each group must be normal.\n",
    "\n",
    "Homogeneity of variance: The variances of the groups must be equal. This means that the variability of the dependent variable within each group must be roughly the same.\n",
    "\n",
    "Independence: The observations must be independent of each other. This means that there should be no relationship between the observations within each grou\n",
    "\n",
    "No outlier should be present: Outliers can impact the validity of ANOVA results because they can distort the mean values of the groups and increase the variance within the groups. In extreme cases, outliers can even create a significant difference between the groups when there is actually no true difference.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. Some examples of violations that could impact the validity of the results are:\n",
    "\n",
    "Non-normality: If the data is not normally distributed, the ANOVA may produce inaccurate results. In such cases, transforming the data (e.g. log transformation) may help to meet the normality assumption.\n",
    "\n",
    "Heteroscedasticity: If the variances of the groups are not equal, the ANOVA may produce inaccurate results. This can be detected using statistical tests such as Levene's test or the Bartlett's test. If heteroscedasticity is detected, a Welch's ANOVA may be used instead.\n",
    "\n",
    "Lack of independence: If the observations are not independent, the ANOVA may produce inaccurate results. This can happen if there is clustering or correlation within the data. In such cases, a mixed-effects ANOVA may be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f4ded3-a57b-4e04-a577-7f54e83cd0f5",
   "metadata": {},
   "source": [
    "2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d94ad8-4a09-44ae-83e3-35bbcf43551c",
   "metadata": {},
   "source": [
    "There are three types of ANOVA: one-way ANOVA, two-way ANOVA, and repeated-measures ANOVA. Each type of ANOVA is used to analyze different types of data and research questions.\n",
    "\n",
    "One-way ANOVA: One-way ANOVA is used when there is only one independent variable (also known as a factor) with two or more levels, and one dependent variable. The purpose of one-way ANOVA is to determine whether there are significant differences between the means of the groups. One-way ANOVA is commonly used in experimental and quasi-experimental designs where researchers want to compare the means of multiple groups on a single dependent variable.\n",
    "For example, a researcher might use one-way ANOVA to test whether there are significant differences in the mean scores of three different treatment groups (e.g. cognitive-behavioral therapy, medication, and placebo) on a measure of depression.\n",
    "\n",
    "Two-way ANOVA: Two-way ANOVA is used when there are two independent variables (factors) with two or more levels each, and one dependent variable. The purpose of two-way ANOVA is to determine whether there are significant main effects of each independent variable, as well as an interaction effect between the two independent variables. Two-way ANOVA is commonly used in experimental designs where researchers want to investigate how two independent variables affect a single dependent variable.\n",
    "For example, a researcher might use two-way ANOVA to test whether there are significant main effects of gender and age on a measure of job satisfaction, as well as an interaction effect between gender and age. \n",
    "\n",
    "\n",
    "Factorial ANOVA is another term for two-way ANOVA. It is called \"factorial\" because it involves analyzing the main effects and interaction effect of two or more factors (independent variables). In a two-way ANOVA, there are two independent variables (factors) that are analyzed simultaneously to determine their effects on the dependent variable.\n",
    "\n",
    "Repeated-measures ANOVA: Repeated-measures ANOVA is used when the same participants are measured on the same dependent variable under different conditions or at different time points. The purpose of repeated-measures ANOVA is to determine whether there are significant differences in the means of the dependent variable across the different conditions or time points. Repeated-measures ANOVA is commonly used in longitudinal studies or within-subjects experimental designs where researchers want to investigate changes in a dependent variable over time or across different conditions.\n",
    "For example, a researcher might use repeated-measures ANOVA to test whether there are significant differences in the mean scores of participants on a measure of anxiety before and after a mindfulness-based intervention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd1581-da0a-47a0-a436-9e9e48227cf7",
   "metadata": {},
   "source": [
    "3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a45948-7918-4dcf-900a-7018d19fb47b",
   "metadata": {},
   "source": [
    "Partitioning of variance is a key concept in ANOVA that refers to the division of the total variance in a dependent variable into separate components that are attributed to different sources of variation. This variance partitioning is performed by ANOVA to determine the relative contributions of different sources of variation to the total variance in the dependent variable.\n",
    "\n",
    "The total variance in a dependent variable can be broken down into three components in a one-way ANOVA:\n",
    "\n",
    "Between-groups variance: This component reflects the differences between the group means and represents the variation in the dependent variable that is due to the effect of the independent variable (i.e., the factor).\n",
    "\n",
    "Within-groups variance: This component reflects the differences within each group and represents the variation in the dependent variable that is not explained by the independent variable.\n",
    "\n",
    "Total variance: This component represents the overall variation in the dependent variable, which is equal to the sum of the between-groups and within-groups variances.\n",
    "\n",
    "In a two-way ANOVA, the total variance is partitioned into four components: the main effect of factor 1, the main effect of factor 2, the interaction effect between factor 1 and factor 2, and the residual (error) variance.\n",
    "\n",
    "Understanding the concept of partitioning of variance is important because it provides valuable information about the sources of variation in the dependent variable. By identifying the relative contributions of different sources of variation to the total variance, researchers can determine which factors have the strongest effect on the dependent variable and how much of the total variation in the dependent variable can be attributed to these factors.\n",
    "\n",
    "Partitioning of variance also helps researchers to interpret the results of ANOVA and draw conclusions about the significance of the effects of the independent variables. By understanding the partitioning of variance, researchers can determine whether the differences between groups or conditions are large enough to be considered statistically significant and meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e8c02-5178-4a44-8116-5a1ddbe0def1",
   "metadata": {},
   "source": [
    "4.  How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual \n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c56abe-92c5-47c4-ad8f-c2b394534db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 9.333333333333337\n",
      "Explained sum of squares (SSE): 1.5\n",
      "Residual sum of squares (SSR): 7.8333333333333375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a pandas DataFrame containing your data\n",
    "data = pd.DataFrame({'group': ['A', 'A', 'B', 'B', 'C', 'C'], 'value': [4, 5, 3, 2, 1, 2]})\n",
    "\n",
    "# Fit a one-way ANOVA model\n",
    "model = ols('value ~ group', data=data).fit()\n",
    "\n",
    "# Extract the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "SST = anova_table['sum_sq'][0]\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "SSE = anova_table['sum_sq'][1]\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print('Total sum of squares (SST):', SST)\n",
    "print('Explained sum of squares (SSE):', SSE)\n",
    "print('Residual sum of squares (SSR):', SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28e341-9243-4938-a58a-17f318f0bf9d",
   "metadata": {},
   "source": [
    "5.  In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e933e0-acd3-4628-b06a-2ff6779e62d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sum_sq   df     F    PR(>F)\n",
      "A            8.0  1.0   6.4  0.064677\n",
      "B           60.5  1.0  48.4  0.002243\n",
      "A:B          2.0  1.0   1.6  0.274577\n",
      "Residual     5.0  4.0   NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'A': ['a1', 'a2', 'a1', 'a2', 'a1', 'a2', 'a1', 'a2'],\n",
    "    'B': ['b1', 'b1', 'b2', 'b2', 'b1', 'b1', 'b2', 'b2'],\n",
    "    'y': [2, 5, 7, 8, 1, 4, 9, 10]\n",
    "})\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "model = ols('y ~ A + B + A:B', data=data).fit()\n",
    "\n",
    "# Extract the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671928b-229a-49b8-953a-33e78f4bce94",
   "metadata": {},
   "source": [
    "In the ols formula, A + B + A:B specifies the main effects of A and B, as well as their interaction effect. The typ=2 argument in the anova_lm function specifies that we want to use the Type II sum of squares method.\n",
    "\n",
    "The resulting ANOVA table will show the sum of squares, degrees of freedom, mean squares, F-statistics, and p-values for the main effects of A and B, as well as their interaction effect. We can use these values to determine whether the effects are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40d04b-aabb-4576-880c-fb638e31a2d8",
   "metadata": {},
   "source": [
    "6.  Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. \n",
    "What can you conclude about the differences between the groups, and how would you interpret these \n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae8d4b-a7c5-4074-8ea3-9ebba85693b8",
   "metadata": {},
   "source": [
    "A one-way ANOVA tests the null hypothesis that the population means of all groups are equal against the alternative hypothesis that at least one of the population means is different from the others.\n",
    "\n",
    "If you obtained an F-statistic of 5.23 and a p-value of 0.02, it means that the differences between the groups are statistically significant at a 95% confidence level (or alpha level of 0.05), and that there is strong evidence against the null hypothesis. In other words, the probability of observing such differences between the groups by chance alone is less than 2%, assuming the null hypothesis is true.\n",
    "\n",
    "Therefore, you can conclude that there is at least one group that has a significantly different population mean from the other groups. However, you cannot determine which specific group(s) have the different mean(s) based on the ANOVA result alone. Additional post-hoc tests or further analysis may be needed to identify the specific group(s) with different means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb8141-a6d7-497c-a5e7-dc6c7b011b4e",
   "metadata": {},
   "source": [
    "7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential \n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22079f55-1831-48dc-94e0-0f73e9a9e745",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, missing data can be handled in different ways. One common approach is to delete the cases with missing data, which is known as complete case analysis. Another approach is to impute the missing values, either by replacing them with the mean, median, or mode of the available data, or by using more sophisticated imputation methods such as multiple imputation.\n",
    "\n",
    "However, the method chosen for handling missing data can have consequences for the results of the analysis. If cases with missing data are deleted, the analysis may suffer from reduced power and biased estimates, particularly if the missing data are not missing completely at random (MCAR). If imputation methods are used, the choice of imputation method can also impact the results of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f68fda-6fe6-4a48-bada-f5371aa61078",
   "metadata": {},
   "source": [
    "8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide \n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b757b-8db8-44c0-bcb5-71cc104c832f",
   "metadata": {},
   "source": [
    "Post-hoc tests are used to compare specific pairs of groups after a significant result is obtained in ANOVA. There are several common post-hoc tests, including Tukey's HSD (Honestly Significant Difference), Bonferroni correction, Scheffe's test, and Fisher's Least Significant Difference (LSD).\n",
    "\n",
    "Tukey's HSD: This test is commonly used when the sample sizes are equal and is considered the most conservative post-hoc test. It calculates the minimum significant difference required to reject the null hypothesis for all possible pairwise group comparisons. Tukey's HSD is the most commonly used post-hoc test and provides a balance between type I and type II errors.\n",
    "\n",
    "Bonferroni correction: This test is used when sample sizes are unequal and requires the researcher to adjust the alpha level (significance level) for each pairwise comparison. Bonferroni correction is more conservative than Tukey's HSD and is recommended when there are a large number of pairwise comparisons.\n",
    "\n",
    "Scheffe's test: This test is used when sample sizes are unequal and there are more than two groups. It is a conservative test that controls the family-wise error rate (FWER), which is the probability of making at least one type I error when multiple tests are conducted. Scheffe's test is more appropriate when the number of groups is small.\n",
    "\n",
    "Fisher's LSD: This test is used when there are only two groups to compare. It is less conservative than Tukey's HSD and Bonferroni correction and is appropriate when there are small sample sizes or unequal variances.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is when a researcher wants to compare the mean heights of individuals from different ethnic groups. After conducting ANOVA, the researcher finds a significant difference between the groups. A post-hoc test could be used to determine which specific groups differ significantly from each other in terms of height."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da9abf-65e3-4c5d-bbcb-5215179b3382",
   "metadata": {},
   "source": [
    "9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from \n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python \n",
    "to determine if there are any significant differences between the mean weight loss of the three diets. \n",
    "Report the F-statistic and p-value, and interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a865cdea-9221-4071-b360-b9f41af6cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 8.914168610576342\n",
      "p-value: 0.00022180999236284595\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# generate some random weight loss data\n",
    "np.random.seed(42) # for reproducibility\n",
    "a = np.random.normal(loc=5, scale=2, size=50)\n",
    "b = np.random.normal(loc=4.5, scale=2, size=50)\n",
    "c = np.random.normal(loc=6, scale=2, size=50)\n",
    "\n",
    "# conduct one-way ANOVA\n",
    "f_stat, p_val = f_oneway(a, b, c)\n",
    "\n",
    "# print the results\n",
    "print('F-statistic:', f_stat)\n",
    "print('p-value:', p_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352de25c-63ca-4089-b16d-037ae908d3c3",
   "metadata": {},
   "source": [
    "In this code, we first generate some random weight loss data for each diet using normal distributions with different means (loc) and standard deviations (scale). Then we conduct a one-way ANOVA using the f_oneway() function from scipy.stats. Finally, we print the F-statistic and p-value.\n",
    "\n",
    "Assuming a significance level of 0.05, we can interpret the results as follows:\n",
    "\n",
    "Since the p-value (0.0022) is less than the significance level of 0.05, we reject the null hypothesis that there is significant difference between the mean weight loss of the three diets. In other words, there is enough evidence to suggest that one diet is better than the others in terms of weight loss. However, this conclusion is based on a simulated dataset with no real-world context and should not be interpreted as a definitive answer for any specific case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d7235-2082-48e4-924d-c1f7d48e0b6a",
   "metadata": {},
   "source": [
    "10. A company wants to know if there are any significant differences in the average time it takes to \n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They \n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to \n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or \n",
    "interaction effects between the software programs and employee experience level (novice vs. \n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9502550-44a7-4346-8c7c-3e70ac907f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             sum_sq    df           F        PR(>F)\n",
      "C(Program)                78.149012   2.0  798.065327  4.829346e-21\n",
      "C(Experience)                   NaN   1.0         NaN           NaN\n",
      "C(Program):C(Experience)  32.868300   2.0  335.654281  2.198477e-16\n",
      "Residual                   1.273000  26.0         NaN           NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 1, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1900: RuntimeWarning: invalid value encountered in divide\n",
      "  F /= J\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a pandas dataframe with the data\n",
    "data = pd.DataFrame({'Program': ['A']*10 + ['B']*10 + ['C']*10,\n",
    "                     'Experience': ['Novice']*15 + ['Experienced']*15,\n",
    "                     'Time': [10.2, 9.7, 9.8, 9.5, 10.1, 10.3, 10.2, 9.9, 9.8, 9.9,\n",
    "                              11.1, 11.2, 11.4, 10.9, 11.3, 10.9, 11.1, 11.5, 11.4, 11.3,\n",
    "                              8.7, 9.0, 9.1, 8.8, 8.6, 8.9, 8.8, 9.2, 9.0, 8.8]})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=data).fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(sm.stats.anova_lm(model, typ=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e18a2e-7d1e-4dd6-b5c7-a08687f5ff89",
   "metadata": {},
   "source": [
    "This code first creates a pandas dataframe with the data, where each row corresponds to a single employee and their assigned software program, experience level, and task completion time.\n",
    "\n",
    "Then, the ols function from the statsmodels.formula.api module is used to fit the two-way ANOVA model to the data. The formula Time ~ C(Program) + C(Experience) + C(Program):C(Experience) specifies the dependent variable (Time) and the independent variables (Program and Experience) as categorical variables, and includes their interaction effect.\n",
    "\n",
    "Finally, the anova_lm function from the statsmodels.stats.anova module is used to print the ANOVA table, which summarizes the results of the analysis, including the sum of squares, degrees of freedom, F-statistics, and p-values for the main effects of Program and Experience, as well as their interaction effect.\n",
    "\n",
    "Interpreting the results, if we find that there is a significant main effect of Program, then we can conclude that there are significant differences in the average time it takes to complete the task using the different software programs. If we find that there is a significant main effect of Experience, then we can conclude that there are significant differences in the average time it takes to complete the task between novice and experienced employees. If we find a significant interaction effect between Program and Experience, then we can conclude that the effect of Program on task completion time depends on the experience level of the employee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ff320-8585-4b8d-a8cf-62f1cdc861e6",
   "metadata": {},
   "source": [
    "11. An educational researcher is interested in whether a new teaching method improves student test \n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the \n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a \n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores \n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which \n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d67fd774-9c50-4a63-a7a4-e5143a3a66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed692863-890f-4973-9f73-9e486dc99063",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_scores = np.array([75, 82, 68, 90, 74, 86, 79, 67, 72, 81, 87, 77, 83, 76, 78, 80, 73, 85, 69, 71])\n",
    "experimental_scores = np.array([88, 90, 81, 92, 83, 87, 91, 84, 89, 85, 86, 82, 93, 80, 94, 79, 78, 95, 96, 97])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09685f11-6a6c-4cf9-b3bb-afb332fd2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(control_scores, experimental_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3547f89a-5131-404c-8cfd-a042549fbe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -4.961778387478812\n",
      "p-value: 1.4958938702427363e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60f37a4a-a4a5-4d3b-bf8f-91c69480d8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj lower   upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental     9.85   0.0 5.8312 13.8688   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#post-hoc test\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(np.concatenate([control_scores, experimental_scores]), np.concatenate([np.repeat('control', len(control_scores)), np.repeat('experimental', len(experimental_scores))]))\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3341728-acf8-41b4-a126-f4871c377968",
   "metadata": {},
   "source": [
    "12.  A researcher wants to know if there are any significant differences in the average daily sales of three \n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store \n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any \n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post\u0002hoc test to determine which store(s) differ significantly from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7053dbc6-3ae8-4ea4-ad64-c1391214397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sum_sq    df         F   PR(>F)\n",
      "store      15.622222   2.0  0.826556  0.44096\n",
      "Residual  822.166667  87.0       NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a sample dataset\n",
    "data = pd.DataFrame({'day': range(1,31),\n",
    "                     'store_a': [20, 25, 30, 23, 19, 18, 26, 21, 24, 22, 19, 28, 30, 27, 20, 25, 22, 19, 24, 21, 18, 29, 25, 23, 22, 26, 24, 27, 19, 20],\n",
    "                     'store_b': [18, 22, 19, 17, 25, 20, 21, 24, 27, 23, 26, 19, 18, 22, 20, 23, 27, 21, 19, 22, 25, 23, 18, 26, 27, 21, 24, 22, 25, 23],\n",
    "                     'store_c': [22, 21, 25, 20, 23, 24, 22, 26, 20, 27, 23, 18, 24, 26, 23, 21, 22, 28, 19, 25, 27, 21, 23, 20, 22, 25, 23, 24, 20, 26]})\n",
    "\n",
    "# convert the dataset from wide to long format\n",
    "data_long = pd.melt(data, id_vars=['day'], value_vars=['store_a', 'store_b', 'store_c'], var_name='store', value_name='sales')\n",
    "\n",
    "# conduct one-way repeated measures ANOVA\n",
    "model = ols('sales ~ store', data=data_long).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76c318bd-012a-41d0-b549-62434ce84d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      " group1  group2 meandiff p-adj   lower  upper  reject\n",
      "-----------------------------------------------------\n",
      "store_a store_b  -0.9667 0.4459 -2.8593  0.926  False\n",
      "store_a store_c     -0.2 0.9656 -2.0926 1.6926  False\n",
      "store_b store_c   0.7667 0.6003  -1.126 2.6593  False\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# conduct Tukey's HSD test\n",
    "posthoc = pairwise_tukeyhsd(data_long['sales'], data_long['store'], alpha=0.05)\n",
    "\n",
    "# print the results of the post-hoc test\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af21753c-213b-4aed-81cf-3b19b5558c21",
   "metadata": {},
   "source": [
    "To conduct a post-hoc test to determine which store(s) differ significantly from each other, we can use Tukey's HSD test. We can use the pairwise_tukeyhsd function from the statsmodels library to conduct this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fb7e7-f5b4-4fd9-ae32-e8e24aa2fccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
